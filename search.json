[
  {
    "objectID": "presentations/template.html#name",
    "href": "presentations/template.html#name",
    "title": "Template Slide Options",
    "section": "",
    "text": "More Info"
  },
  {
    "objectID": "presentations/template.html#section",
    "href": "presentations/template.html#section",
    "title": "Template Slide Options",
    "section": "",
    "text": "Materials\n\n\n\nSecond of the two one-day workshops\nShiny in Production with Golem\nPretty cool to have Joe Cheng, the original creator of the Shiny framework, as a TA"
  },
  {
    "objectID": "presentations/template.html#section-2",
    "href": "presentations/template.html#section-2",
    "title": "Template Slide Options",
    "section": "",
    "text": "Module UI\npicker_ui &lt;- function(id) {\n\n  ns &lt;- NS(id)\n  \n  tagList(\n  \n    # UI FEATURES\n    \n    )\n  \n}\n\n\n\n\nModule Server\npicker_server &lt;- function(id, \n                          sets_rv){\n  moduleServer(\n    id,\n    function(input, \n             output, \n             session) {\n      # SERVER LOGIC\n    }\n  )\n}\n\n\n\n\n\nEasily Added to Apps\n# app_ui.R\nmod_picker_ui(\"picker_1\")\n\n# app_server.R\ninput_ids &lt;- mod_picker_server(\"picker_1\")\n\n\nSource"
  },
  {
    "objectID": "presentations/template.html#section-3",
    "href": "presentations/template.html#section-3",
    "title": "Template Slide Options",
    "section": "",
    "text": "This part justâ€¦\nappears when the slide opens\n\n\n\nThis part requires clicking\na\nb\nc"
  },
  {
    "objectID": "presentations/template.html#.resources",
    "href": "presentations/template.html#.resources",
    "title": "Template Slide Options",
    "section": "",
    "text": "Workshops\n\nBig Data in R with Arrow\nIntro to Shiny\nShiny in Production\nGetting Started with Quarto\n\n\n\n\n\n\n\nTalks\n\nAbstractions all the way down\nIncrease Accessibility\nShinyUIEditor\nParameterized Quarto Reports\nMagic with WASM and WebR\nPandem-2\nFull Posit 2023 Playlist"
  },
  {
    "objectID": "presentations/20240124-BWG.html#section",
    "href": "presentations/20240124-BWG.html#section",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "",
    "text": "More Info\n\n\n\nRStudio was founded in 2009 with the vision of creating high-quality open-source software for data scientists with initial focus on the R community\nThey invested heavily in open-source development, education, and community growth through their IDE (of the same name), conferences, and package development\nThis focus on open-source software often comes into conflict with the imperatives of sustaining a commercial enterprise when shareholder profit trumps customer interests\nIn order to avoid those pitfalls RStudio reincorporated asâ€¦"
  },
  {
    "objectID": "presentations/20240124-BWG.html#section-1",
    "href": "presentations/20240124-BWG.html#section-1",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "",
    "text": "More Info\n\n\n\nA public benefit corporation with\n\nHigh standards of transparency and accountability\nFiduciary responsibility to address social, economic, and environmental needs while still overseeing business goals\n\nThe intent is to remain independent over the long term while remaining committed to open source, broadening focus to be more inclusive of other languages (notably Python), and continue to grow the community\nThe RStudio IDE will remain the same\nThis conference started out with two one-day workshops on Sunday and Monday before the conference proper began"
  },
  {
    "objectID": "presentations/20240124-BWG.html#.arrow",
    "href": "presentations/20240124-BWG.html#.arrow",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "",
    "text": "Materials\n\n\n\nFirst of the two one-day workshops\nBig Data in R with Arrow\nThe workshop focused on using an R interface to Apache Arrow to process larger-than-memory files and multi-file datasets with arrow using familiar dplyr syntax.\nMain reason? â€¦"
  },
  {
    "objectID": "presentations/20240124-BWG.html#section-2",
    "href": "presentations/20240124-BWG.html#section-2",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "",
    "text": "To avoid the over use of memory that leads to seg faults and crashing your R session"
  },
  {
    "objectID": "presentations/20240124-BWG.html#big-data-in-r-with-arrow",
    "href": "presentations/20240124-BWG.html#big-data-in-r-with-arrow",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Big Data in R with Arrow",
    "text": "Big Data in R with Arrow\n\nWhat is Arrow?\n\nA toolbox\nDesigned to improve\n\nAlgorithm performance\nData transfer efficiency\n\n\n\n\n\nA multi-language toolbox for accelerated data interchange and in-memory processing\nIt defines a memory format and provides libraries for interaction\nArrow is designed to both improve the performance of analytical algorithms and the efficiency of moving data from one system or programming language to another"
  },
  {
    "objectID": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-1",
    "href": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-1",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Big Data in R with Arrow",
    "text": "Big Data in R with Arrow\n\nAccomplished via in-memory columnar format\n\nStandardized\nLanguage agnostic\n\nInteraction via Arrow libraries\n\nC, C++, C#, Go, Java, JavaScript, Julia, MATLAB, Python, R, Ruby, and Rust.\n\n\n\n\nAccomplished via an in-memory columnar format for representing structured, table-like data sets in-memory.\nStandardized, language-agnostic specification\nInteraction with this format is via Arrowâ€™s libraries\nLibraries are available for C, C++, C#, Go, Java, JavaScript, Julia, MATLAB, Python, R, Ruby, and Rust."
  },
  {
    "objectID": "presentations/20240124-BWG.html#section-3",
    "href": "presentations/20240124-BWG.html#section-3",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "",
    "text": "Source\n\n\n\nThe columnar format in question\nParquet files take advantage of the latest SIMD (Single Instruction, Multiple Data) operations included in modern processors\n\nEssentially: Your processor can process more data in parallel across multiple files and portions of files.\n\nTheyâ€™re able to do this due to a hybrid contiguous columnar layout used in data storage that improves read speeds over 30x and reduces storage space by &gt;80%\nThe only downside is theyâ€™re slightly less intuitive to the user"
  },
  {
    "objectID": "presentations/20240124-BWG.html#section-4",
    "href": "presentations/20240124-BWG.html#section-4",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "",
    "text": "Source\n\n\n\nHere is a comparison to serialization of CSV and pure column based storage formats\nParquet files use a hybrid method to sequentially store chunks of columns along with limited metadata about them"
  },
  {
    "objectID": "presentations/20240124-BWG.html#section-5",
    "href": "presentations/20240124-BWG.html#section-5",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "",
    "text": "Source\n\n\n\nThis hybrid storage makes them especially useful for both\n\nprojection: selecting certain columns for the user, does not have to traverse the entire file as it would with CSV\npredicates: identifying certain rows based on criteria in a specific column, easiest in row-based storage as can be accomplished with sorting\n\nData science requires both of these and for efficiencyâ€™s sake needs to traverse as little of the file as possible in doing so"
  },
  {
    "objectID": "presentations/20240124-BWG.html#section-6",
    "href": "presentations/20240124-BWG.html#section-6",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "",
    "text": "Source\n\n\n\nParquet files leverage metadata to skip parts of the data that can be excluded according to the chosen predicate: for eg. Int &lt; 5\nSkip reading parts of the file or entire files when they are partitioned appropriately\nParquet files also take advantage of"
  },
  {
    "objectID": "presentations/20240124-BWG.html#parquet",
    "href": "presentations/20240124-BWG.html#parquet",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Parquet",
    "text": "Parquet\n\nFurther optimizations\n\nRun length encoding for duplicate values\nDictionary encoding for long strings\nProjection and predicate pushdown\n\n\n\n\nRLE encodes sequential duplicates by storing the value and the count of times it consecutively repeats reducing storage and read times\nLike storing factors in R Dictionary encoding replaces values with small integers and stores the mapping separately.\nSelect only the necessary columns (projection) and rows (predicate) during the data read process.\nAll in all Parquet is a phenomenal data storage format for speed, size, and efficiency\nWhy does that matter in the context of this workshopâ€¦"
  },
  {
    "objectID": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-2",
    "href": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-2",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Big Data in R with Arrow",
    "text": "Big Data in R with Arrow\n\nNYC Taxi Dataset\n\nBIG data\n&gt;40Gb on disk\n&gt; 1.15 billion rows\n\n\n\n\nThis workshop had us examining truly gigantic data\nToo large for loading into memory on just about any machine\nThis data was downloaded onto our machines in preparation for the course and was partitioned across multiple folders and files by year and month a process which took hours"
  },
  {
    "objectID": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-3",
    "href": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-3",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Big Data in R with Arrow",
    "text": "Big Data in R with Arrow\n\narrow::open_dataset()\n\nPointer to data (in arrow)\nBuild queries as normal with dplyr\n\n\n\n\nWorkhorse is open_dataset\nCall it to point to a directory of parquet files or a single large one and return a Dataset pointer\nQueries are built against that pointer using dplyr verbs as if against a tibble\nQuery is not evaluated at this time, nothing moved to memory"
  },
  {
    "objectID": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-4",
    "href": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-4",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Big Data in R with Arrow",
    "text": "Big Data in R with Arrow\n\narrow::compute()\narrow::collect()\n\n\n\nEvaluation of queries is blazingly fast as it relies on C++ libraries\ncompute() evaluates the query, in-memory output stays in Arrow\ncollect() evaluates the query, in-memory output returns to R"
  },
  {
    "objectID": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-5",
    "href": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-5",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Big Data in R with Arrow",
    "text": "Big Data in R with Arrow\n\nnrow()\nhead(), select(), filter(), and collect()\nacross()\n\n\n\nMostly familiar dplyr verbs for interaction with the results\nnrow() to work out how many rows of data your analyses will return\ncompute() when you need to execute intermediate steps\ncollect() to pull all of the data into your R session\nhead(), select(), filter(), and collect() to preview results\nacross() to manipulate data in multiple columns at once"
  },
  {
    "objectID": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-6",
    "href": "presentations/20240124-BWG.html#big-data-in-r-with-arrow-6",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Big Data in R with Arrow",
    "text": "Big Data in R with Arrow\n\nEfficiently read + filter + join + summarise massive datasets\nLeverage Parquet file format and C++ libraries\nSimple interaction via queries build with dplyr\n\n\n\nWhy use Arrow?\nEfficiently read + filter + join + summarise massive datasets\nLeverage Parquet file format and fast C++ libraries\nSimple interaction via queries build with dplyr\nThe course included a good amount of practice using Arrow on large datasets\nSo far application in our context of mostly SQL databases has been limited"
  },
  {
    "objectID": "presentations/20240124-BWG.html#.shiny",
    "href": "presentations/20240124-BWG.html#.shiny",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "",
    "text": "Materials\n\n\n\nSecond of the two one-day workshops\nShiny in Production with Golem\nPretty cool to have Joe Cheng, the original creator of the Shiny framework, as a TA"
  },
  {
    "objectID": "presentations/20240124-BWG.html#shiny-in-production",
    "href": "presentations/20240124-BWG.html#shiny-in-production",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Shiny in Production",
    "text": "Shiny in Production\n\n\nIntro Shiny\n\n\n\nShiny is an R package that makes it easy to build interactive web apps straight from R.\nYou can host standalone apps on a webpage or embed them in R Markdown documents or build dashboards or any number of things.\nYou can also extend your Shiny apps with CSS themes, htmlwidgets, and JavaScript actions.\nChallenges often emerge when these applications are deployed beyond the developerâ€™s machine or developed beyond a minimal size"
  },
  {
    "objectID": "presentations/20240124-BWG.html#shiny-in-production-1",
    "href": "presentations/20240124-BWG.html#shiny-in-production-1",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Shiny in Production",
    "text": "Shiny in Production\n\n\n\nProblems with performance bottlenecks, crashes, simultaneous user issues, optimization, and un-managed complexity tend to arise when these applications grow beyond their initial ideation\nPart of that is due to many apps being designed as a prototype and turning into a full blown web app\nEven more troubles arise when connecting to external data sources, other execution backends, and incorporating numerous other R packages\nThis sort of ballooning complexity makes collaboration, modification, and debugging much more difficult\nAll of a sudden your shiny app is looking decidedly less so"
  },
  {
    "objectID": "presentations/20240124-BWG.html#shiny-in-production-2",
    "href": "presentations/20240124-BWG.html#shiny-in-production-2",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Shiny in Production",
    "text": "Shiny in Production\n\n\n\nEnter the Golem framework for building shiny apps\nScripts guide you with first steps akin to {usethis} & {devtools}\nEncourages Shiny best practices by providing structure and guardrails\nProduce shiny apps as R packages to ensure dependencies are met"
  },
  {
    "objectID": "presentations/20240124-BWG.html#shiny-in-production-3",
    "href": "presentations/20240124-BWG.html#shiny-in-production-3",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Shiny in Production",
    "text": "Shiny in Production\n\n\n\n01_start.R for original setup\n02_dev.R in for ongoing work\n03_deploy.R for deployment\n\n\nâ”œâ”€â”€ DESCRIPTION\nâ”œâ”€â”€ NAMESPACE\nâ”œâ”€â”€ R\nâ”‚   â”œâ”€â”€ app_config.R\nâ”‚   â”œâ”€â”€ app_server.R\nâ”‚   â”œâ”€â”€ app_ui.R\nâ”‚   â””â”€â”€ run_app.R\nâ”œâ”€â”€ dev\nâ”‚   â”œâ”€â”€ 01_start.R\nâ”‚   â”œâ”€â”€ 02_dev.R\nâ”‚   â”œâ”€â”€ 03_deploy.R\nâ”‚   â””â”€â”€ run_dev.R\nâ”œâ”€â”€ inst\nâ”‚   â”œâ”€â”€ app\nâ”‚   â”‚   â””â”€â”€ www\nâ”‚   â”‚       â””â”€â”€ favicon.ico\nâ”‚   â””â”€â”€ golem-config.yml\nâ””â”€â”€ man\n    â””â”€â”€ run_app.Rd\n\n\n\nSource\n\n\n\nDev scripts get you started and keep you rolling.\nThey initially create your description, readme and license files, add version control and tests\nUse them to add dependencies, create custom functions, and modularize your shiny code\nWhen ready the scripts in 03 ease deployment to shiny hosting servers, docker containers, etc through checking code, building the package, and generating appropriate configs"
  },
  {
    "objectID": "presentations/20240124-BWG.html#shiny-in-production-4",
    "href": "presentations/20240124-BWG.html#shiny-in-production-4",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Shiny in Production",
    "text": "Shiny in Production\n\n\n\nApp Scripts live in R/ directory\nDefined front end (UI) and back end (server)\n\n\nâ”œâ”€â”€ DESCRIPTION\nâ”œâ”€â”€ NAMESPACE\nâ”œâ”€â”€ R\nâ”‚   â”œâ”€â”€ app_config.R\nâ”‚   â”œâ”€â”€ app_server.R\nâ”‚   â”œâ”€â”€ app_ui.R\nâ”‚   â””â”€â”€ run_app.R\nâ”œâ”€â”€ dev\nâ”‚   â”œâ”€â”€ 01_start.R\nâ”‚   â”œâ”€â”€ 02_dev.R\nâ”‚   â”œâ”€â”€ 03_deploy.R\nâ”‚   â””â”€â”€ run_dev.R\nâ”œâ”€â”€ inst\nâ”‚   â”œâ”€â”€ app\nâ”‚   â”‚   â””â”€â”€ www\nâ”‚   â”‚       â””â”€â”€ favicon.ico\nâ”‚   â””â”€â”€ golem-config.yml\nâ””â”€â”€ man\n    â””â”€â”€ run_app.Rd\n\n\n\nSource\n\n\n\nUI and Server scripts define the front and back end code of your\nModules are also added here"
  },
  {
    "objectID": "presentations/20240124-BWG.html#shiny-in-production-5",
    "href": "presentations/20240124-BWG.html#shiny-in-production-5",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Shiny in Production",
    "text": "Shiny in Production\n\n\n\n\nApp Scripts live in R/ directory\n\n\n\nModules in individual files\n\nEncapsulate and repeat features\nPrevent collisions\nLogical organization\nEasier debugging\n\n\n\nâ”œâ”€â”€ DESCRIPTION\nâ”œâ”€â”€ NAMESPACE\nâ”œâ”€â”€ R\nâ”‚   â”œâ”€â”€ app_config.R\nâ”‚   â”œâ”€â”€ app_server.R\nâ”‚   â”œâ”€â”€ app_ui.R\nâ”‚   â”œâ”€â”€ mod_picker.R\nâ”‚   â””â”€â”€ run_app.R\nâ”œâ”€â”€ dev\nâ”‚   â”œâ”€â”€ 01_start.R\nâ”‚   â”œâ”€â”€ 02_dev.R\nâ”‚   â”œâ”€â”€ 03_deploy.R\nâ”‚   â””â”€â”€ run_dev.R\nâ”œâ”€â”€ inst\nâ”‚   â”œâ”€â”€ app\nâ”‚   â”‚   â””â”€â”€ www\nâ”‚   â”‚       â””â”€â”€ favicon.ico\nâ”‚   â””â”€â”€ golem-config.yml\nâ””â”€â”€ man\n    â””â”€â”€ run_app.Rd\n\n\n\nSource\n\n\n\nModules allow you to encapsulate distinct app interfaces\nAvoids namespace collisions when using same widget across different areas of your app\nOrganize code into logical and easy-to-understand components\nFacilitate collaboration and easy debugging"
  },
  {
    "objectID": "presentations/20240124-BWG.html#shiny-in-production-6",
    "href": "presentations/20240124-BWG.html#shiny-in-production-6",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Shiny in Production",
    "text": "Shiny in Production\n\n\n\n\nModule UI\npicker_ui &lt;- function(id) {\n\n  ns &lt;- NS(id)\n  \n  tagList(\n  \n    # UI FEATURES\n    \n    )\n  \n}\n\n\n\n\nModule Server\npicker_server &lt;- function(id, \n                          sets_rv){\n  moduleServer(\n    id,\n    function(input, \n             output, \n             session) {\n      # SERVER LOGIC\n    }\n  )\n}\n\n\n\n\n\nEasily Added to Apps\n# app_ui.R\nmod_picker_ui(\"picker_1\")\n\n# app_server.R\ninput_ids &lt;- mod_picker_server(\"picker_1\")\n\n\nSource\n\n\n\nAn example module for a UI picker element (numbers, groups, etc)\nUI\n\nid: String to use for namespace\nns &lt;- NS(id): Create proper namespace function\nHTML taglist of UI elements to return\n\nServer\n\nLogic is encapsulated with namespace applied\n\nAdd to app easily\n\nCopy/paste the included module calling functions\nUse as many times as you like with different names\npicker_1, picker_2, etc"
  },
  {
    "objectID": "presentations/20240124-BWG.html#shiny-in-production-7",
    "href": "presentations/20240124-BWG.html#shiny-in-production-7",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Shiny in Production",
    "text": "Shiny in Production\n\n{profvis}\n{crew}\nShiny + Arrow\n{shinyloadtest}\n\n\nSource\n\n\n\nAlso covered a number of important aspects including:\n\nProfiling your Shiny app with {profvis}\nAsynchronous processes with {crew}\nA further exploration of fast data loading/querying with {arrow} & .parquet files\nLoad testing\n\nAbsolutely cram packed day but lots of good content\n\nCurrently preparing a rewrite of the Surveiller app to take advantage of these improvements"
  },
  {
    "objectID": "presentations/20240124-BWG.html#abstractions-all-the-way-down",
    "href": "presentations/20240124-BWG.html#abstractions-all-the-way-down",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Abstractions All the Way Down",
    "text": "Abstractions All the Way Down\n\nâ€œAn abstractionâ€ is the outcome of a process of deriving general rules and concepts from specific examples â€” a concept that acts as a common noun for all subordinate concepts and connects any related concepts as a group, field, or category.\n\n\n\nIn software engineering and computer science, abstraction is the process of generalizing concrete details, such as attributes, away from the study of objects and systems to focus attention on details of greater importance.\n\n\nSource\n\n\n\nAs systems become more complex, we must rely on more abstractions.\nEach abstraction tries to hide complexity, allowing more focus on the more important details\nMostly donâ€™t care how the results get done layers below the abstraction youâ€™re dealing with, this applies in computer science as well as in organizational structures\n\nCS: write code in high level programming language, maybe need to know vaguely how the compiler works in order to debug\nOS: request from CEO that is passed down corp structure to the people and machines that actually do the work\n\nWhy do we use abstractions? â€¦"
  },
  {
    "objectID": "presentations/20240124-BWG.html#abstractions-all-the-way-down-1",
    "href": "presentations/20240124-BWG.html#abstractions-all-the-way-down-1",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Abstractions All the Way Down",
    "text": "Abstractions All the Way Down\n\nHead trunk only hold so much junk\n\n\nConstrain complexity and separate concerns\n\n\nAll non-trivial abstractions, to some degree, are leaky\n\n\n\nFrom djikstra: the competent programmer is fully aware of the limited size of his own skull\nWith the complexity of the modern world / workplace we cannot be masters of everything\nAccording to Joe Spolsky who wrote a great article called the Law of Leaky Abstractions: All nonâ€¦\nSpolskyâ€™s article gives examples of an abstraction that works most of the time, but where a detail of the underlying complexity cannot be ignored, thus leaking complexity out of the abstraction back into the software that uses the abstraction. This results in abstraction failure: unexpected results, errors, incorrect responses"
  },
  {
    "objectID": "presentations/20240124-BWG.html#abstractions-all-the-way-down-assertions",
    "href": "presentations/20240124-BWG.html#abstractions-all-the-way-down-assertions",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Abstractions All the Way Down: Assertions",
    "text": "Abstractions All the Way Down: Assertions\n\nAbstractions can leak so they must be permeable\nNo abstraction is right for everyone\n\n\n\nJDâ€™s assertions about abstractions were as follows"
  },
  {
    "objectID": "presentations/20240124-BWG.html#abstractions-all-the-way-down-solutions",
    "href": "presentations/20240124-BWG.html#abstractions-all-the-way-down-solutions",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Abstractions All the Way Down: Solutions",
    "text": "Abstractions All the Way Down: Solutions\n\nAbstraction permeability allows for debugging\n\nCommunication is key\n\nâ€œMeet people where they areâ€\n\n80-16-4 split of normal/advanced/guru users\n\n\n\n\nâ€¦ Holds for organizations and computers\n\nCommunication of owndership, responsibility, code visibilty, etc\n\nWhat is fast becoming the ethos of the computation and operational genomics group â€¦\n\nMatch the abstraction to the person needing\ndonâ€™t jump 0 to 100 and burn down their process to creat an API or a LIMS database before helping troubleshoot and improve the Excel theyâ€™re currently having issue with\n\nExcellent talk, highly recommend"
  },
  {
    "objectID": "presentations/20240124-BWG.html#session-roundup",
    "href": "presentations/20240124-BWG.html#session-roundup",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "Session Roundup",
    "text": "Session Roundup\n\nCommit to Change: How to Increase Accessibility in Your Favorite Open Source Projects\nShinyUiEditor: From Alpha to Powerful Shiny App Development Tool\nParameterized Quarto Reports Improve Understanding of Soil Health\nMagic with WebAssembly and webR\nAutomating the Dutch National Flu Surveillance for Pandemic Preparedness\n\n\n\nCall to arms to improve accessibility of docs and packages\nBrilliant tool to allow visual editing of a Shiny UI that creates the server / UI code automatically\nImpressive commitment to customization in reporting based on a few simple rules\nRunning shiny without a server in a web browser, frankly mindblowing the possibilities\nHeartening to see the shared challenges we and the Dutch National Flu Surveillance program faced along with similar solutions"
  },
  {
    "objectID": "presentations/20240124-BWG.html#.resources",
    "href": "presentations/20240124-BWG.html#.resources",
    "title": "Insights and Innovations from Posit Conf 2023",
    "section": "",
    "text": "Workshops\n\nBig Data in R with Arrow\nIntro to Shiny\nShiny in Production\nGetting Started with Quarto\n\n\n\n\n\n\n\nTalks\n\nAbstractions all the way down\nIncrease Accessibility\nShinyUIEditor\nParameterized Quarto Reports\nMagic with WASM and WebR\nPandem-2\nFull Posit 2023 Playlist"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "quarto-presentations",
    "section": "",
    "text": "Best Practices in R\n\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2024\n\n\nAdrian Zetner\n\n\n\n\n\n\n  \n\n\n\n\nInsights and Innovations from Posit Conf 2023\n\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2024\n\n\nAdrian Zetner\n\n\n\n\n\n\n  \n\n\n\n\nReproducibility with renv\n\n\n\n\n\n\n\n\n\n\n\n\nJul 4, 2023\n\n\nAdrian Zetner\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "presentations/20230704-renv.html#sharing-r-analyses-with-collaborators",
    "href": "presentations/20230704-renv.html#sharing-r-analyses-with-collaborators",
    "title": "Reproducibility with renv",
    "section": "Sharing R Analyses with Collaborators",
    "text": "Sharing R Analyses with Collaborators\n\nâ€œI tried to run your code but it says Iâ€™m missing Xâ€ ğŸ˜Ÿ\nâ€œYour code used to run fine but now itâ€™s not workingâ€ ğŸ˜–\nâ€œI upgraded my software and now your code is junkâ€ ğŸ’”\n\nWeâ€™ve all been here. Headaches coming from code that weâ€™ve written and are proud of but canâ€™t be used by our colleagues or no longer works for them. The"
  },
  {
    "objectID": "presentations/20230704-renv.html#reproducibility-in-data-driven-analysis",
    "href": "presentations/20230704-renv.html#reproducibility-in-data-driven-analysis",
    "title": "Reproducibility with renv",
    "section": "Reproducibility in Data Driven Analysis",
    "text": "Reproducibility in Data Driven Analysis\n\nCrucial for collaboration and transparency in science\nSoftware and package versions can differ between computers\nPotential code failure or inconsistent results\nSolution: Replicate the environment\n\n\n- Reproducibility in analysis is crucial for collaboration and transparency in science.\n- Even with free and open-source software and clean code, software and package versions can differ between computers.\n- Differences in software versions, package versions, and external dependencies can lead to code failure or inconsistent results.\n- One solution is to replicate the environment in which the code was developed to ensure compatibility and result consistency."
  },
  {
    "objectID": "presentations/20230704-renv.html#replicate-the-environment",
    "href": "presentations/20230704-renv.html#replicate-the-environment",
    "title": "Reproducibility with renv",
    "section": "Replicate the environment â™Š",
    "text": "Replicate the environment â™Š\n\nManual replication of the environment is impractical\nPotential solutions\n\nVirtual environments (Python, Conda, etc)\nDocker\nBinder/Jupyter Notebooks\n\n\n\n- Manual replication of the environment is impractical, prompting the need for automated solutions.\n- Solutions range from ensuring consistent package versions to replicating the entire computer environment.\n- Virtual environments to install elements from packages up to system libraries (python, conda, etc)\n- Docker containers package applications into portable images to run consistently in almost any environment\n- Binder and jupyter make sharing online from github etc easy"
  },
  {
    "objectID": "presentations/20230704-renv.html#virtual-environments",
    "href": "presentations/20230704-renv.html#virtual-environments",
    "title": "Reproducibility with renv",
    "section": "Virtual Environments ğŸŒŒ",
    "text": "Virtual Environments ğŸŒŒ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython virtual environments are folders containing a complete copy of the Python stack used to create them.\nThey consist of a separate python executable, the associated stack, and a site-packages folder for installed Python packages.\nVirtual environments ensure full isolation by handling package installations independently.\nThey are easy to understand and use but can be heavyweight due to the duplication of the Python stack and packages for each environment.\nConda is a language-agnostic tool for package management and environment management. As a package manager, Conda can install, update and remove packages. As an environment manager, it can manage virtual environments. Itâ€™s robust and broadly applicable but not useable in all contexts"
  },
  {
    "objectID": "presentations/20230704-renv.html#containers",
    "href": "presentations/20230704-renv.html#containers",
    "title": "Reproducibility with renv",
    "section": "Containers ğŸ",
    "text": "Containers ğŸ\n\n\n\n\n\n\n\n\n\nDocker containers are lightweight relative to true virtual machines and create isolated environments that package applications and their dependencies into a standardized unit\nDeveloping docker containers comes with increased overhead both from complexity in development and deployment along with potential security concerns and performance limitations\nNot exactly what we want to have to focus on when sharing data analysis with colleagues"
  },
  {
    "objectID": "presentations/20230704-renv.html#notebooks",
    "href": "presentations/20230704-renv.html#notebooks",
    "title": "Reproducibility with renv",
    "section": "Notebooks ğŸ“‘",
    "text": "Notebooks ğŸ“‘\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote book options\nBinder is aÂ freeÂ service that creates a virtual computer in the cloud based on the specifications listed in a GitHub repository. In the process of building the environment, Binder also clones the GitHub repository making it painless to reproduce analyses. It is essentially read-only though and while great for sharing analyses it can be slow to load and easy to lose work\nJupyter notebooks integrate code and its output into a single document that combines visualizations, narrative text, mathematical equations, and other rich media. In other words: itâ€™s a single document where you can run code, display the output, and also add explanations, formulas, charts, and make your work more transparent, understandable, repeatable, and shareable. Great for sharing analyses, somewhat limited by software needed to run\nThese all seem like a lot of work simply to share our projects with other people, enterâ€¦"
  },
  {
    "objectID": "presentations/20230704-renv.html#r-projects",
    "href": "presentations/20230704-renv.html#r-projects",
    "title": "Reproducibility with renv",
    "section": "R Projects ğŸ“‚",
    "text": "R Projects ğŸ“‚\n\n\n\nProjects are the organizational tool of RStudio, essentially a folder\nOrganize all aspects of an analysis (raw data, R scripts, external scripts, outputs, documentation, etc) within a root directory\nAllows for relative pathing amongst all elements\nAllows for simultaneous analyses in different folders and siloing those from each other"
  },
  {
    "objectID": "presentations/20230704-renv.html#packages",
    "href": "presentations/20230704-renv.html#packages",
    "title": "Reproducibility with renv",
    "section": "Packages ğŸ“¦",
    "text": "Packages ğŸ“¦\n\nExtend base R with more functionality\nCalled libraries or packages in other languages\nCan require compilation on your machine (source) or pre-compiled as a binary package\n\n\nExtend base R with more functionality Called libraries or packages in other languages Can require compilation on your machine (source) or pre-compiled as a binary package\nBinary packages offer several advantages such as Faster installation, Platform compatibility, Dependency resolution, and greater Security when installed from trusted sites. When binary packages are unavailable (OS differences etc) they must be compiled locally.\nInstalled fromâ€¦"
  },
  {
    "objectID": "presentations/20230704-renv.html#repositories",
    "href": "presentations/20230704-renv.html#repositories",
    "title": "Reproducibility with renv",
    "section": "Repositories ğŸ›ï¸",
    "text": "Repositories ğŸ›ï¸\n\nSource of packages ğŸ“¦\nMany different available\n\nCRAN\nBioconductor\nPosit Public Package Manager\nR Universe\n\n\n\n\nA repository is a source of packages.\nThe main repository for R packages is CRAN (Comprehensive R Archive Network), which is accessible in almost every R session.\nOther freely available repositories include Bioconductor, Posit (formerly RStudio) Public Package Manager, and R Universe.\nWhen a package is retrieved from a repository it is installed on your computer to a library"
  },
  {
    "objectID": "presentations/20230704-renv.html#libraries",
    "href": "presentations/20230704-renv.html#libraries",
    "title": "Reproducibility with renv",
    "section": "Libraries ğŸ“š",
    "text": "Libraries ğŸ“š\n\nStore packages installed for current R version\nSystem libraries\n\nUser\nSite\nDefault\n\n\n\nA library in R is a directory that contains installed packages.\nThree system libraries: a user library, a site library, and a default library where base R packages are installed.\nGenerally, you donâ€™t have to worry about libraries and can install all packages into a system library shared across projects.\nSometimes changes to packages can break functionality in older projects.\nWith the use of renv, you can employ project libraries, which provide each project with its own separate set of packages."
  },
  {
    "objectID": "presentations/20230704-renv.html#project-local-libraries-with-renv",
    "href": "presentations/20230704-renv.html#project-local-libraries-with-renv",
    "title": "Reproducibility with renv",
    "section": "Project Local Libraries with renv ğŸ“š",
    "text": "Project Local Libraries with renv ğŸ“š\n\nProject local dependency management\nStore and restore your project dependencies\nMimic Packrat\nLittle to no change to workflows\n\n\n\nProject local dependency management\nStore and restore your project dependencies\nMimic Packrat\nLittle to no change to workflows\n\nOK, so we have the concepts of projects, packages, libraries, and repositories down now, correct? So the natural extension of that is to individualize dependencies to a single project in order to save and load the state of your project as you wrote it. renv is designed to more robustly mimic much of the functionality of the now defunct packrat package with fewer surprises and better default behaviours. The philosophy behind renv is that your project workflow shouldnâ€™t meaningfully change due to incorporating it into your projects."
  },
  {
    "objectID": "presentations/20230704-renv.html#workflow",
    "href": "presentations/20230704-renv.html#workflow",
    "title": "Reproducibility with renv",
    "section": "Workflow ğŸ”€",
    "text": "Workflow ğŸ”€\n\nInitialize a new project local environment with a private R library with renv::init()\nWork in the project as normal adding packages with install.packages()\nSave the state of the working project with renv::snapshot() to lock file (renv.lock)\nKeep working with the option to save state after successful changes (renv::snapshot()) or revert to previous if updates introduce new problems (renv::restore())\n\n\nThe general workflow when working withÂ renvÂ is: 1. CallÂ [renv::init()](../reference/init.html)Â to initialize a new project-local environment with a private R library\n2. Work in the project as normal, installing and removing new R packages as they are needed in the project\n3. CallÂ [renv::snapshot()](../reference/snapshot.html)Â to save the state of the project library to the lockfile (calledÂ renv.lock)\n4. Keep working with the option to save state after successful changes (renv::snapshot()) or revert to previous if updates introduce new problems (renv::restore())"
  },
  {
    "objectID": "presentations/20230704-renv.html#initialize",
    "href": "presentations/20230704-renv.html#initialize",
    "title": "Reproducibility with renv",
    "section": "Initialize âœ¨",
    "text": "Initialize âœ¨\n\nSearches R scripts for implicitly included dependencies using dependencies()\n\nlibrary(\"dplyr\")\ndplyr::mutate()\n\nCopy discovered packages into theÂ renvÂ global package cache for re-use\nMissingÂ RÂ package dependencies are installed into the projectâ€™s private library\nInitial lockfile capturing the state of the projectâ€™s library is created\nThe project is activated withÂ activate()\n\n\nWhat does renv actually do when you call init? The primary steps taken when initializing a new project are:\n1. RÂ package dependencies are discovered within theÂ RÂ files used within the project withÂ [dependencies()](dependencies.html)\n2. Discovered packages are copied into theÂ renvÂ global package cache, so these packages can be re-used across future projects as necessary\n3. Any missingÂ RÂ package dependencies discovered are then installed into the projectâ€™s private library\n4. A lockfile capturing the state of the projectâ€™s library is created withÂ [snapshot()](snapshot.html)\n5. The project is activated withÂ [activate()](activate.html) which adds the necessary code to the projectâ€™s .Rprofile to use the projectâ€™s own library on start up"
  },
  {
    "objectID": "presentations/20230704-renv.html#initialize---infrastructure-files",
    "href": "presentations/20230704-renv.html#initialize---infrastructure-files",
    "title": "Reproducibility with renv",
    "section": "Initialize - Infrastructure & Files âœ¨",
    "text": "Initialize - Infrastructure & Files âœ¨\n\n\n\n\n\n\n\nFile\nUsage\n\n\n\n\n.Rprofile\nUpdated to activateÂ renvÂ for new project R sessions\n\n\nrenv.lock\nThe lockfile\n\n\nrenv/\nFolder containing all environment details\n\n\nrenv/activate.R\nActivation script run by the projectÂ .Rprofile.\n\n\nrenv/library\nThe private project library\n\n\nrenv/settings.json\nProject settings\n\n\nrenv/.gitignore\nrenv specific gitignore\n\n\n\n\n\nProject Rprofile with appended activation scripts\nLockfile describing the state of your projectâ€™s library at some point in time.\nProject subfolder that holds all the the important environment details like: Activation script, project library, settings, and .gitignore\n.Rprofile,Â renv.lockÂ andÂ renv/activate.RÂ files should be committed to your version control system which is usually done by renv::init(). Changes to settings.json should also be tracked."
  },
  {
    "objectID": "presentations/20230704-renv.html#renv.lock",
    "href": "presentations/20230704-renv.html#renv.lock",
    "title": "Reproducibility with renv",
    "section": "renv.lock ğŸ”’",
    "text": "renv.lock ğŸ”’\n\n\n\nVersion of renv\n\nVersion of R\nR repositories active for lockfile\n\nPackage records\n\n\n{\n  \"R\": {\n    \"Version\": \"4.2.3\",\n    \"Repositories\": [\n      {\n        \"Name\": \"CRAN\",\n        \"URL\": \"https://cloud.r-project.org\"\n      }\n    ]\n  },\n  \"Packages\": {\n    \"markdown\": {\n      \"Package\": \"markdown\",\n      \"Version\": \"1.0\",\n      \"Source\": \"Repository\",\n      \"Repository\": \"CRAN\",\n      \"Hash\": \"4584a57f565dd7987d59dda3a02cfb41\"\n    },\n    \"here\": {\n      \"Package\": \"here\",\n      \"Version\": \"0.7\",\n      \"Source\": \"Repository\",\n      \"Repository\": \"CRAN\",\n      \"Hash\": \"908d95ccbfd1dd274073ef07a7c93934\"\n    }\n  }\n}\n\n\n\nrenvÂ uses aÂ lockfileÂ to capture the state of your library at some point in time. It is stored as a collection ofÂ records, with different records defining:\n\nThe version ofÂ renvÂ used when generating the lockfile;\nThe version ofÂ RÂ used in that project;\nThe R repositories that were active when the lockfile was created;\nPackage recordsÂ defining each R package, their version, and their installation source.\n\nHere is an example lockfile, including the packagesÂ markdownÂ andÂ here"
  },
  {
    "objectID": "presentations/20230704-renv.html#cache",
    "href": "presentations/20230704-renv.html#cache",
    "title": "Reproducibility with renv",
    "section": "Cache ğŸ¦",
    "text": "Cache ğŸ¦\n\nGlobal package installation location shared across all projects\nProject specific libraries built from symlinks to cache\nPrimary benefits:\n\nSpeed up renv::restore() and renv::install()\nSave disk space\n\n\n\nOne ofÂ renvâ€™s primary features is the use of a global package cache, which is shared across all projects usingÂ renv. This means that project specific libraries are actually built from symlinks to the userâ€™s cache\nTheÂ renvÂ package cache provides two primary benefits:\n\nFuture calls toÂ [renv::restore()](../reference/restore.html)Â andÂ [renv::install()](../reference/install.html)Â will become much faster, asÂ renvÂ will be able to find and re-use packages already installed in the cache.\n\nBecause it is not necessary to have duplicate versions of your packages installed in each project, theÂ renvÂ cache should also help you save disk space relative to an approach with project-specific libraries without a global cache."
  },
  {
    "objectID": "presentations/20230704-renv.html#cache-1",
    "href": "presentations/20230704-renv.html#cache-1",
    "title": "Reproducibility with renv",
    "section": "Cache ğŸ¦",
    "text": "Cache ğŸ¦\n\nInstall process\n\nInstallation requested\nAvailable? Link, otherwise install.\nCopy to cache\nLink back to project\n\nLocation\n\nDefault to ~/.local/share/renv\nMultiple locations allowed\n\n\n\nThe process by which packages enter the cache is roughly as follows:\n\nPackage installation is requested via e.g.Â [install.packages()](https://rdrr.io/r/utils/install.packages.html), orÂ [renv::install()](../reference/install.html), or as part ofÂ [renv::restore()](../reference/restore.html).\nIfÂ renvÂ is able to find the requested version of the package in the cache, then that package is linked into the project library, and installation is complete.\n\nOtherwise, the package is downloaded and installed into the project library.\n\nAfter installation of the package has successfully completed, the package is then copied into the global package cache, and then linked back into the project library.\n\nRenv defaults to the userâ€™s home .local folder but multiple locations cache locations can be indicated and shared between users. If using a shared cache the time and disk savings can be leveraged across many users"
  },
  {
    "objectID": "presentations/20230704-renv.html#shims",
    "href": "presentations/20230704-renv.html#shims",
    "title": "Reproducibility with renv",
    "section": "Shims ğŸ”¼",
    "text": "Shims ğŸ”¼\n\n\n\nFunction\nShim\n\n\n\n\ninstall.packages()\nrenv::install()\n\n\nremove.packages()\nrenv::remove()\n\n\nupdate.packages()\nrenv::update()\n\n\n\n\nTo help you take advantage of the package cache,Â renvÂ places a couple of shims (or aliases) on the search path - Package related functions like install/remove/update from the utils package become renv functions In effect, callingÂ [install.packages()](https://rdrr.io/r/utils/install.packages.html)Â within anÂ renvÂ project will callÂ [renv::install()](../reference/install.html)Â instead. This can be useful when installing packages which have already been cached. For example, if you useÂ renv::install(\"dplyr\"), andÂ renvÂ detects that the latest version on CRAN has already been cached, thenÂ renvÂ will just install using the copy available in the cache â€“ thereby skipping some of the installation overhead. This can be disabled but is a really lovely convenience feature."
  },
  {
    "objectID": "presentations/20230704-renv.html#isolation",
    "href": "presentations/20230704-renv.html#isolation",
    "title": "Reproducibility with renv",
    "section": "Isolation ğŸ«§",
    "text": "Isolation ğŸ«§\n\nRequire that all packages be distributed with a project\nrenv::isolate(): copies all dependencies into the local library\nVastly increases project folder size\nNo reliance on external libraries\n\n\n\nSometimes one requires that a project can be distributed in a more contained fashion with all packages included in a zip file.\nRenvâ€™s isolate function copies all dependencies in the project library from the cache into the project folder: project can be zipped and shared at the cost of a large increase of folder size"
  },
  {
    "objectID": "presentations/20230704-renv.html#collaboration---setup",
    "href": "presentations/20230704-renv.html#collaboration---setup",
    "title": "Reproducibility with renv",
    "section": "Collaboration - Setup âš’ï¸",
    "text": "Collaboration - Setup âš’ï¸\n\nCreate a new project repository and folder\nOne user explicitly initializes renv in the version controlled project folder\nCommit all files including renv generated ones\nrenv will now bootstrap the project environment on collaborators computers\n\n\n\nOne user (perhaps yourself) should explicitly initializeÂ renvÂ in the project, viaÂ [renv::init()](../reference/init.html). This will create the initialÂ renvÂ lockfile, and also write theÂ renvÂ auto-loaders to the projectâ€™sÂ .RprofileÂ andÂ renv/activate.R. These will ensure the right version ofÂ renvÂ is downloaded and installed for your collaborators when they start in this project.\nShare your project sources, alongside the generated lockfileÂ renv.lock. Be sure to also share the generated auto-loaders inÂ .RprofileÂ andÂ renv/activate.R.\nWhen a collaborator first launches in this project,Â renvÂ should automatically bootstrap itself, thereby downloading and installing the appropriate version ofÂ renvÂ into the project library. After this has completed, they can then useÂ [renv::restore()](../reference/restore.html)Â to restore the project library locally on their machine."
  },
  {
    "objectID": "presentations/20230704-renv.html#collaboration---workflow",
    "href": "presentations/20230704-renv.html#collaboration---workflow",
    "title": "Reproducibility with renv",
    "section": "Collaboration - Workflow ğŸ”€",
    "text": "Collaboration - Workflow ğŸ”€\n\nEnsure all collaborators using the same package version\n\nInstall and test locally\nSnapshot project\nShare lockfile\nRestore locally\n\nLockfile changes can be viewed with renv::history()\n\n\nWhile working on a project, you or your collaborators may need to update or install new packages in your project. When this occurs, youâ€™ll also want to ensure your collaborators are then using the same newly-installed packages. In general, the process looks like this: 1. A user installs, or updates, one or more packages in their local project library; 2. That user callsÂ [renv::snapshot()](../reference/snapshot.html)Â to update theÂ renv.lockÂ lockfile;\n3. That user then shares the updated version ofÂ renv.lockÂ with their collaborators;\n4. Other collaborators then callÂ [renv::restore()](../reference/restore.html)Â to install the packages specified in the newly-updated lockfile.\nA bit of care is required if collaborators wish to update the sharedÂ renv.lockÂ lockfile concurrently â€“ in particular, if multiple collaborators are installing new packages and updating their own local copy of the lockfile, then conflicts would need to be sorted out afterwards.\nOne way to guard against this it to use a version control system, and have all collaborators work off the same branch. This way, if someone needs to updateÂ renv.lockÂ in the public repository, all collaborators will see that updated lockfile and will gain access to it next time they pull those changes. Depending on the size of your team, you may want to ensure any changes toÂ renv.lockÂ are communicated so that everyone knows and understands when and why packages have been installed or updated."
  },
  {
    "objectID": "presentations/20230704-renv.html#caveats",
    "href": "presentations/20230704-renv.html#caveats",
    "title": "Reproducibility with renv",
    "section": "Caveats â˜ ï¸",
    "text": "Caveats â˜ ï¸\n\nNot a panacea for reproducibility\nSolves one part of the problem\n\nRecords R and package versions\nTools to reinstall above\n\nProblems\n\nResults may depend on other system components\nPackages may be removed from repositories\n\n\n\nIt is important to emphasize thatÂ renv is not a panacea for reproducibility. Rather, it is a tool that can help make projects reproducible by solving one small part of the problem: it records the version of R + R packages being used in a project, and provides tools for reinstalling the declared versions of those packages in a project. Ultimately, making a project reproducible requires some thoughtfulness from the user: what does it mean for a particular project to be reproducible, and how canÂ renvÂ (and other tools) be used to accomplish that particular goal of reproducibility?\nThere are a still a number of factors that can affect whether this project could truly be reproducible in the future â€“ for example,\n\nThe results produced by a particular project might depend on other components of the system itâ€™s being run on â€“ for example, the operating system itself, the versions of system libraries in use, the compiler(s) used to compile R and the R packages used, and so on. Keeping a â€˜stableâ€™ machine image is a separate challenge, butÂ DockerÂ is one popular solution. See alsoÂ [vignette(\"docker\", package = \"renv\")](../articles/docker.html)Â for recommendations on how Docker can be used together withÂ renv.\nThe R packages that the project depends on may no longer be available. If your project depends on R packages available on CRAN, itâ€™s possible those packages may be removed in the future â€“ either by request of the package maintainer, or by the maintainers of CRAN itself. This is quite rare, but needs consideration if reproducibility of a project is paramount.\n\nIn addition, be aware that package installation may fail if a package was originally installed through a CRAN-available binary, but that binary is no longer available.Â renvÂ will attempt to install the package from sources in this situation, but attempts to install from source can (and often do) fail due to missing system prerequisites for compilation of a package. TheÂ [renv::equip()](../reference/equip.html)Â function may be useful in these scenarios, especially on Windows: it will download external software commonly used when compiling R packages from sources, and instruct R to use that software during compilation.\nA salient example of this is theÂ rmarkdownÂ package, as it relies heavily on theÂ pandocÂ command line utility. However, because pandoc is not bundled with theÂ rmarkdownÂ package (it is normally provided by RStudio, or installed separately by the user), simply restoring anÂ renvÂ project usingÂ rmarkdownÂ may not be sufficient â€“ one also needs to ensure the project is run in a environment with the correct version ofÂ pandocÂ available."
  },
  {
    "objectID": "presentations/20230704-renv.html#use-case---shiny",
    "href": "presentations/20230704-renv.html#use-case---shiny",
    "title": "Reproducibility with renv",
    "section": "Use Case - ShinyğŸŒŸ",
    "text": "Use Case - ShinyğŸŒŸ\n\nShiny apps utilize site library\nChanges to one appâ€™s dependencies can break others\n\nEg. dplyr update from version 1.0.10 to 1.1.12 replaced summarise() with reframe()\nInstalling new dplyr to system library breaks older apps\n\nSolution:\n\nInitialize renv project in shiny app dir (shared shiny user cache)\nRestore lockfile to symlink and install all dependencies to app local library\nInclude sourcing of renv/activate.R in app.R\n\nNow Shiny apps can rely on some shared packages and some unique packages\nEasier addition of more shiny apps without clobbering existing"
  },
  {
    "objectID": "presentations/20230704-renv.html#when-to-use-renv",
    "href": "presentations/20230704-renv.html#when-to-use-renv",
    "title": "Reproducibility with renv",
    "section": "When to Use renv",
    "text": "When to Use renv\n\nCollaborating on project and sharing results\nEnsure forward compatibility\nProject small enough to not warrant using more intense encapsulation\nUse of more robust encapsulation problematic (eg. Docker on Shiny Server)"
  },
  {
    "objectID": "presentations/20230704-renv.html#questions",
    "href": "presentations/20230704-renv.html#questions",
    "title": "Reproducibility with renv",
    "section": "Questions?",
    "text": "Questions?"
  },
  {
    "objectID": "presentations/20230704-renv.html#use-case---operational-reports",
    "href": "presentations/20230704-renv.html#use-case---operational-reports",
    "title": "Reproducibility with renv",
    "section": "Use Case - Operational Reports",
    "text": "Use Case - Operational Reports\n\nUpdating dplyr caused a change in the functionality of if_else() where Surveiller relied on the\n\n\nHot off the presses."
  },
  {
    "objectID": "presentations/20240131-RBP.html#seminar-goals",
    "href": "presentations/20240131-RBP.html#seminar-goals",
    "title": "Best Practices in R",
    "section": "Seminar Goals",
    "text": "Seminar Goals\n\nWhat to take away from this seminar\n\nIdeas, resources, methods to improve future work\n\nWhat not to take away from this seminar\n\nAny rush to apply these ideas retroactively to all previous projects\n\nInspiration and content from sources listed at the end\n\n\n\nWhat to take away from this seminar\n\nIdeas, resources, methods to improve future work\n\nWhat not to take away from this seminar\n\nAny rush to apply these ideas retroactively to all previous projects\nDo it while revisiting old projects if you have time and where appropriate\n\n\nInspiration and content from sources listed at the end: donâ€™t worry about too many notes"
  },
  {
    "objectID": "presentations/20240131-RBP.html#table-of-contents",
    "href": "presentations/20240131-RBP.html#table-of-contents",
    "title": "Best Practices in R",
    "section": "Table of Contents",
    "text": "Table of Contents\n\nProject Oriented Workflow\nReadability\nReproducibility"
  },
  {
    "objectID": "presentations/20240131-RBP.html#why",
    "href": "presentations/20240131-RBP.html#why",
    "title": "Best Practices in R",
    "section": "Why?",
    "text": "Why?\n\nWork on More Than One Thing at a Time\nTeam Collaboration\n\nEasier concurrent work\nEasy distribution\n\nStart and Stop\n\nFlexible work schedule\nCheckpoint to save progress\n\nDocumentation for Continuity\n\nEasy resumption\nContext and guidelines for collaborators\n\n\n\nWork on More Than One Thing at a Time\n\nIf waiting for input from a colleague or for an analysis to finish can start another part of the project or another project independently (self-contained).\n\nCollaborate, Communicate, Distribute\n\nTeam Collaboration:\n\nFoster collaboration within a team by structuring the project to enable concurrent contributions.\nKeeping projects self-contained facilitates easy distribution to team members and reporting.\n\n\nStart and Stop\n\nFlexible Work Sessions:\n\nEmbrace a flexible work schedule, allowing for starting and stopping based on availability and focus.\nRegularly checkpoint the project to save progress.\n\nDocumentation for Continuity:\n\nUtilize thorough documentation for easy resumption and provide context and guidelines for others taking over or collaborating.\nThis includes future you!"
  },
  {
    "objectID": "presentations/20240131-RBP.html#how",
    "href": "presentations/20240131-RBP.html#how",
    "title": "Best Practices in R",
    "section": "How?",
    "text": "How?\n\nStandardized organization of files per project\nConsistent actions\n\n\n\nDedicated directories with standardized organization of files per project\nConsistent action focused workflow"
  },
  {
    "objectID": "presentations/20240131-RBP.html#organization-of-project-directories-1",
    "href": "presentations/20240131-RBP.html#organization-of-project-directories-1",
    "title": "Best Practices in R",
    "section": "Organization of Project Directories ğŸ“‚",
    "text": "Organization of Project Directories ğŸ“‚\n\nProject Organization:\n\nFolder per project\nTop-level advertisement\n\nRStudio/Git/{here} characteristic files\n\n\nPath Construction with here():\n\nUtilize here() function\nhere package\nPaths relative to top-level\n\n\n\n\nOrganize each logical project into a folder on your computer.\nMake sure the top-level folder advertises itself as such. This can be as simple as having an empty file named .here\nOr, if you use RStudio and/or Git, those both leave characteristic files behind that will get the job done.\nPath Construction with here():\nUse the here() function from the here package to build the path when you read or write a file.\n\nCreate paths relative to the top-level directory"
  },
  {
    "objectID": "presentations/20240131-RBP.html#here-package",
    "href": "presentations/20240131-RBP.html#here-package",
    "title": "Best Practices in R",
    "section": "{here} Package ğŸ“‚",
    "text": "{here} Package ğŸ“‚\nhere() displays top-level folder location\n\nlibrary(here)\nhere()\n\n[1] \"C:/Users/azetner/Documents/quarto-presentations\"\n\n\n\nSource\n\n\n\nhere() displays top-level folder location\nCriteria for top level\n\nIs a file named .here present?\nIs this an RStudio Project? Literally, can I find a file named something like foo.Rproj?\nIs this an R package? Does it have a DESCRIPTION file?\nIs this a checkout from a version control system? Does it have a directory named .git or .svn?"
  },
  {
    "objectID": "presentations/20240131-RBP.html#here-package-1",
    "href": "presentations/20240131-RBP.html#here-package-1",
    "title": "Best Practices in R",
    "section": "{here} Package ğŸ“‚",
    "text": "{here} Package ğŸ“‚\nBuild a path to a file in a subdirectory and use it\n\nhere(\"presentations\", \"20240131-RBP_images\", \"analysisworkflow.png\")\n\n[1] \"C:/Users/azetner/Documents/quarto-presentations/presentations/20240131-RBP_images/analysisworkflow.png\"\n\nhere(\"presentations/20240131-RBP_images/\")\n\n[1] \"C:/Users/azetner/Documents/quarto-presentations/presentations/20240131-RBP_images\"\n\narrow.file &lt;- here(\"presentations/20240124-BWG_images/arrow_dataset.png\")\n\nfile.info(arrow.file)[\"size\"]\n\n                                                                                                     size\nC:/Users/azetner/Documents/quarto-presentations/presentations/20240124-BWG_images/arrow_dataset.png 79441\n\n\n\nSource\n\n\n\nBuild a path to something in a subdirectory and use it\nThis is taken directly from Jenny Bryanâ€™s github ode to the here package\nNow files within the project are easily accessible from a standardized format regardless of where the access began\n\nRmd files look for subdirs under their location which if theyâ€™re organized into a docs folder Data wonâ€™t be a subdir\n\nEasily passable to another user / computer\nFile locations can be more easily built programmatically\nContinuing on with folder structureâ€¦"
  },
  {
    "objectID": "presentations/20240131-RBP.html#folder-structure",
    "href": "presentations/20240131-RBP.html#folder-structure",
    "title": "Best Practices in R",
    "section": "Folder Structure ğŸ“‚",
    "text": "Folder Structure ğŸ“‚\n\n\n\n\n\nFolder Structure:\n\nData\nCode\nDocumentation\nExternal scripts\nOutputs\n\nStart project from root\n\nConsole or IDE\nhere() for paths\n\n\n\n\n\n\nSeparate folders for data, code, documentation, external scripts, and outputs\nUse subdirectories for clarity and organization\nStart R from top-level\n\nUse {here} for paths\nMaintain top-level working directory\n\nAbsolute paths generated at runtime"
  },
  {
    "objectID": "presentations/20240131-RBP.html#rstudio-projects",
    "href": "presentations/20240131-RBP.html#rstudio-projects",
    "title": "Best Practices in R",
    "section": "RStudio Projects ğŸ“‚",
    "text": "RStudio Projects ğŸ“‚\n\n\n\nMaintain project separation\nSettings stored in &lt;NAME&gt;.Rproj.\nOpen Project in RStudio:\n\nDedicated R process\nFile browser points to Project directory.\nWorking directory set to Project.\n\n\n\nVersion: 1.0\nRestoreWorkspace: No\nSaveWorkspace: No\nAlwaysSaveHistory: Default\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\nRnwWeave: Sweave\nLaTeX: pdfLaTeX\nAutoAppendNewline: Yes\nStripTrailingWhitespace: Yes\nLineEndingConversion: Native\nBuildType: Package\nPackageUseDevtools: Yes\nPackageInstallArgs: --no-multiarch --with-keep.source\nPackageRoxygenize: rd,collate,namespace\n\n\n\n\nRStudio Projects maintain project folder architecture\nRStudio leaves notes to itself in &lt;NAME&gt;.Rproj\n\nincluding settings for starting new sessions, code style choices, and external libraries\n\nOpen Project = dedicated instance of RStudio\n\nDedicated R process\nFile browser pointed at Project directory\nWorking directory set to Project directory\n\nSo youâ€™re working in a project but what does that look like? It consists of a series ofâ€¦"
  },
  {
    "objectID": "presentations/20240131-RBP.html#rstudio-projects-1",
    "href": "presentations/20240131-RBP.html#rstudio-projects-1",
    "title": "Best Practices in R",
    "section": "RStudio Projects ğŸ“‚",
    "text": "RStudio Projects ğŸ“‚\n\n\n\nSettings stored in &lt;NAME&gt;.Rproj.\nOpen Project in RStudio:\n\nDedicated R instance.\nFile browser points to Project directory.\nWorking directory set to Project.\n\n\n\nVersion: 1.0\nRestoreWorkspace: No\nSaveWorkspace: No\nAlwaysSaveHistory: Default\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\nRnwWeave: Sweave\nLaTeX: pdfLaTeX\nAutoAppendNewline: Yes\nStripTrailingWhitespace: Yes\nLineEndingConversion: Native\nBuildType: Package\nPackageUseDevtools: Yes\nPackageInstallArgs: --no-multiarch --with-keep.source\nPackageRoxygenize: rd,collate,namespace\n\n\n\n\nRStudio leaves notes to itself in &lt;NAME&gt;.Rproj\nOpen Project = dedicated instance of RStudio\n\nDedicated R process\nFile browser pointed at Project directory\nWorking directory set to Project directory"
  },
  {
    "objectID": "presentations/20240131-RBP.html#section",
    "href": "presentations/20240131-RBP.html#section",
    "title": "Best Practices in R",
    "section": "",
    "text": "Teams Reactions to show who uses RStudio or not\nRStudio is great for maintaining projects"
  },
  {
    "objectID": "presentations/20240131-RBP.html#save-source-not-the-workspace-environment",
    "href": "presentations/20240131-RBP.html#save-source-not-the-workspace-environment",
    "title": "Best Practices in R",
    "section": "Save Source not the Workspace / Environment ğŸ’¥",
    "text": "Save Source not the Workspace / Environment ğŸ’¥\n\nLivestock vs.Â Pets Analogy from Cloud Computing\n\nLivestock: managed in herds, disposable\nPets: unique, precious\n\nTreat R processes like livestock\n\nWorkspace disposability\nNon-reproducible workflows lead to heartache\n\nExplicitly save important objects\nCheckpoints for long generation time objects\nDesign away fear of reproducibility\n\n\n\nâ€œLivestock is managed in herds and there is little fuss when individuals are lost or must be sacrificed. A pet, on the other hand, is unique and precious.â€\ncultivate a workflow in which you treat R processes (a.k.a. â€œsessionsâ€) like livestock. Any individual R process and the associated workspace is disposable\nif your workspace is a pet, i.e.Â it holds precious objects and you arenâ€™t 100% sure you can reproduce them, you are guaranteeing heartache\nExplicitly save important objects generated during analysis\nCheckpoints for long generation time objects:\n\nIsolate each computational or time demanding step in its own script and write the precious object to file\nCan simply reload the object from file while developing downstream scripts\n\nDesign your code to explicitly ensure the environment is reproducible\nWhatâ€™s the best way to ensure youâ€™re not too precious about your workspaces?"
  },
  {
    "objectID": "presentations/20240131-RBP.html#use-a-blank-slate",
    "href": "presentations/20240131-RBP.html#use-a-blank-slate",
    "title": "Best Practices in R",
    "section": "Use a Blank Slate ğŸ’¥",
    "text": "Use a Blank Slate ğŸ’¥\n\n\n\n\n\n\n\n\n\n\n\n\nR --no-save --no-restore-data\n\n\n\n\nWipe your workspace every load\nThis can be set in RStudio global options\nor via command line\nThis ensures you donâ€™t rely on precious objects in your R environment being loaded from the projectâ€™s .Rdata files"
  },
  {
    "objectID": "presentations/20240131-RBP.html#restart-r-often",
    "href": "presentations/20240131-RBP.html#restart-r-often",
    "title": "Best Practices in R",
    "section": "Restart R often ğŸ’¥",
    "text": "Restart R often ğŸ’¥\n\n\n\n\n\n\n\nRestart R to wipe environment\nSave code not workspaces\nPressure to reinforce correct behaviours\n\nEnsuring source code recreates important artefacts\n\n\n\n\n\nRestart R in RStudio with ctrl+shift+F10, Why?\nRestart R to wipe environment\nSave code not workspaces\nPressure to reinforce correct behaviours\n\nEnsuring source code recreates important objects\n\nSaving code â€“ not workspaces â€“ is incredibly important because it is an absolute requirement for reproducibility. Renouncing .Rdata and restarting R often are not intrinsically important or morally superior behaviours. They are important because they provide constant pressure for you to do the right thing: save the source code needed to create all important artefacts of your analysis.\nReplacing the herd with an identical one is what weâ€™re pushing for. Thereâ€™s no replacing your precious pets\nWhat best practices to follow while consistently completing these actions?"
  },
  {
    "objectID": "presentations/20240131-RBP.html#use-an-ide",
    "href": "presentations/20240131-RBP.html#use-an-ide",
    "title": "Best Practices in R",
    "section": "Use an IDE âš¡",
    "text": "Use an IDE âš¡\n\n\n\nUse an Integrated Development environment to smooth this workflow, I recommend RStudio\nRStudio, VSCode, VIM, whatever\nTake advantage of code-aware editor that will help you notice simple errors like typos and unclosed brackets as well as offering many was to direct code to a running R process. Using an IDE encourages saving code in source files (R/Rmd) rather than sending commands directly to the console\nUse it to organize your workflow and guide towards best practices\nâ€œSometimes people resist the advice to use an IDE because itâ€™s hard to incorporate into their current workflow and dismiss it as something â€œfor experts onlyâ€. But this gets the direction of causality backwards: long-time and professional coders donâ€™t have good habits because they use an IDE. They use an IDE because it makes it so much easier to follow best practices and build good habits.â€\nAn IDE only helps you keep organized with how you work on software, but there is much more to it"
  },
  {
    "objectID": "presentations/20240131-RBP.html#software-management",
    "href": "presentations/20240131-RBP.html#software-management",
    "title": "Best Practices in R",
    "section": "Software Management âš¡",
    "text": "Software Management âš¡\n\nResearch Code and Software:\n\nVaried forms and sizes\nIncludes code processing research data, scripts, and workflows\nScriptable languages like R, Python, shell, etc\nStandalone programs for specific research tasks\n\n\n\nThere are many different shapes and sizes of research software: - Includes code processing research data, scripts, and workflows: any code that runs in order to process your research data. - Any scriptable language (R, Python, shell, etc.) - Standalone programs for specific research tasks - We have to manage it to have a record of all the steps used to process your data"
  },
  {
    "objectID": "presentations/20240131-RBP.html#software-management-1",
    "href": "presentations/20240131-RBP.html#software-management-1",
    "title": "Best Practices in R",
    "section": "Software Management âš¡",
    "text": "Software Management âš¡\n\n\nWhat can go wrong with research code?\n\nWhat does code do?\nWhy did we do it this way?\nNo longer works\nAccuracy at question\n\nSoftware projects all can benefit modular code:\n\nReadable\nReusable\nTestable\n\n\n\n\nWhat can go wrong? I donâ€™t remember what this code does I donâ€™t remember why I made this choice This code doesnâ€™t work any more Iâ€™m not sure if this calculation is correct\nThese can all be attenuated by adopting a few Software Engineering practices the main one being writing modular code - Focus on making code that is modular as it makes the code - Readable - Reusable - Testable\nModular code should be built of functionsâ€¦"
  },
  {
    "objectID": "presentations/20240131-RBP.html#software-management-2",
    "href": "presentations/20240131-RBP.html#software-management-2",
    "title": "Best Practices in R",
    "section": "Software Management âš¡",
    "text": "Software Management âš¡\n\n\n\n\n\n\n\n\nComment brief explanations\nFunctions first\n\nClear inputs and outputs\nMeaningful names\nOne main task\n\nRuthlessly eliminate duplication\n\nFunctions\nData Structures\nEffort\n\n\n\n\n\n\nA function is a reusable section of software that can be treated as a black box by the rest of the program. This is like the way we combine actions in everyday life. Suppose that it is teatime. You could get a teabag, put the teabag in a mug, boil the kettle, pour the boiling water into the mug, wait 3 minutes for the tea to brew, remove the teabag, and add milk if desired. It is much easier to think of this as a single function, â€œmake a cup of teaâ€.\nWhen weâ€™re writing scripts built of functions we should think of it in much the same way and apply certain rules to each\nGive them a brief Description: Short is fine; always include at least one example of how the program is used. Remember, a good example is worth a thousand words: Where possible, the description should also indicate reasonable values for parameters, dependencies, etc\nBuild programs out of short, single-purpose functions with:\n\nclearly-defined inputs and outputs\nmeaningful names (applies to variables too), considering tab completion and name based on scope (counter can be i, major object should have a name that describes its purpose)\n\nFunctions should have one main task, which can be combined into larger functions or workflows or if they get too complex, broken down again into single task functions\n\nâ€œMake a cup of Teaâ€ shouldnâ€™t include â€œTake out the garbageâ€ but it should contain smaller functions to â€œBoil Kettleâ€ â€œprepare cup with teabagâ€ etc\n\nEliminate duplication:\nFunction Usage:\n\nWrite and re-use functions.\nAvoid copy-pasting code.\n\nData Structure Utilization:\n\nUse data structures like lists where possible over multiple related objects\nPrefer creating a single structure (e.g., score = (1, 2, 3)) over multiple closely-related variables (e.g., score1, score2, score3).\n\nEffort:\n\nLook for well-maintained libraries before writing your own\nSeek existing code for specific functions.\nExplore language-specific library catalogs (e.g., CRAN for R, PyPI for Python).\nTest libraries before relying on them."
  },
  {
    "objectID": "presentations/20240131-RBP.html#software-management-3",
    "href": "presentations/20240131-RBP.html#software-management-3",
    "title": "Best Practices in R",
    "section": "Software Management âš¡",
    "text": "Software Management âš¡\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSplit monolithic scripts into smaller, individual, independent portions\nTalk about image\nThis software needs something to work on so lets talk aboutâ€¦"
  },
  {
    "objectID": "presentations/20240131-RBP.html#data-management",
    "href": "presentations/20240131-RBP.html#data-management",
    "title": "Best Practices in R",
    "section": "Data Management ğŸ’½",
    "text": "Data Management ğŸ’½\n\nWhy Data Management?\n\nData loss / corruption\nConfusion about provenance\nVersion\n\n\n\n\nData loss / corruption: anything that makes it unusable\nConfusion about provenance: eg. source? purpose?\nVersion: eg. what workflow generated the data?"
  },
  {
    "objectID": "presentations/20240131-RBP.html#data-management-1",
    "href": "presentations/20240131-RBP.html#data-management-1",
    "title": "Best Practices in R",
    "section": "Data Management ğŸ’½",
    "text": "Data Management ğŸ’½\n\nData Management\n\nSave the raw data\nEnsure raw data is backed up\nCreate analysis-friendly data\n\nCreate the data you wish to see in the world\n\nSelf explanatory naming\nOpen formats\nMachine readability\n\nExport cleaned data that you wish youâ€™d received\n\nRecord all the steps used to process data\n\n\n\n\nSave data in its original form to ensure faithful retention for rerunning analyses, recovering from mishaps, and experimenting fearlessly. Consider making raw data read only and resist them temptation to overwrite with cleaned results\nFor data thatâ€™s impractical to manage this way, document the exact procedure, version details, and other pertinent information when working with large, stable databases.\nBack up raw data in multiple places: if itâ€™s not backed up it doesnâ€™t matter\nAnalysis friendly data\n\nReplace inscrutable variable and column names with self explanatory, machine-readable alternatives\nConvert data from closed, proprietary formats to open, non-proprietary formats like CSV for tabular data, JSON, YAML, or XML for non-tabular data\nCreate an ideal dataset by focusing on improving machine and human readability without extensive filtering or adding external information. Prioritize machine readability for easy reuse"
  },
  {
    "objectID": "presentations/20240131-RBP.html#data-management-2",
    "href": "presentations/20240131-RBP.html#data-management-2",
    "title": "Best Practices in R",
    "section": "Data Management ğŸ’½",
    "text": "Data Management ğŸ’½\n\n\n\n\n\n\n\n\n\n\nEach variable must have its own column\nEach observation must have its own row\nEach value must have its own cell\n\n\n\n\nConsistency\nVectorization\n\n\n\n\nSource\n\n\n\nOne common type of analysis friendly data is Tidy data\nThere are three interrelated rules which make a dataset tidy\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\nWhy bother? Thereâ€™s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, itâ€™s easier to learn the tools that work with it because they have an underlying uniformity.\n\nThereâ€™s a specific advantage to placing variables in columns because it allows Râ€™s vectorised nature to shine. As you learned in mutate and summary functions, most built-in R functions work with vectors of values. That makes transforming tidy data feel particularly natural.\n\nThere are two main reasons to use other data structures:\n\nAlternative representations may have substantial performance or space advantages.\nSpecialised fields have evolved their own conventions for storing data that may be quite different to the conventions of tidy data."
  },
  {
    "objectID": "presentations/20240131-RBP.html#data-management-3",
    "href": "presentations/20240131-RBP.html#data-management-3",
    "title": "Best Practices in R",
    "section": "Data Management ğŸ’½",
    "text": "Data Management ğŸ’½\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn much the same way we donâ€™t want monolithic scripts, we also donâ€™t want data transformation to be an entire black box\nTalk about image\n\nProprietary format to open machine readable\nInterim scripts put out interim results to be reports for environment recreation. Livestock, not pets"
  },
  {
    "objectID": "presentations/20240131-RBP.html#naming-conventions",
    "href": "presentations/20240131-RBP.html#naming-conventions",
    "title": "Best Practices in R",
    "section": "Naming Conventions ğŸ“‘",
    "text": "Naming Conventions ğŸ“‘\n\nFile names should be:\n\nMachine readable\nHuman readable\nOptional: Consistent\nOptional: Play well with default ordering\n\n\n\n\nFile names should be:\n\nMachine readable\nHuman readable\nOptional: Consistent\nOptional: Play well with default ordering"
  },
  {
    "objectID": "presentations/20240131-RBP.html#machine-readable",
    "href": "presentations/20240131-RBP.html#machine-readable",
    "title": "Best Practices in R",
    "section": "Machine Readable ğŸ“‘",
    "text": "Machine Readable ğŸ“‘\n\n\n\nRegex/Globbing Friendly\n\nAvoid spaces, punctuation, and accented characters\nMaintain case sensitivity\n\nEasy Computation\n\nUse intentional delimiters for straightforward computational processes\nDeliberate delimiter use enhances computational efficiency\n\nDashes for spaces between words\nUnderscores for chunks\n\n\n\n\n\n\n20220120_patient-exposure_control.csv\n20220120_patient-exposure_treatment.csv\n20220215_patient-exposure_control.csv\n20220215_patient-exposure_treatment.csv\n20220215_patient-info_control.csv\n20220310_patient-info_control.csv\n20220520_patient-info_treatment.csv\n20220805_patient-info_control.csv\n20230120_patient-info_treatment.csv\n20230215_patient-info_treatment.csv\n20230310_patient-exposure_control.csv\n20230310_patient-exposure_treatment.csv\n20230405_patient-exposure_control.csv\n20230405_patient-exposure_treatment.csv\n20230405_patient-info_control.csv\n20230615_patient-info_treatment.csv\n20230710_patient-info_control.csv\n20230710_patient-info_treatment.csv\n20230805_patient-info_treatment.csv\n\n\nâ¯ ls -1 2022*\n20220120_patient-exposure_control.csv\n20220120_patient-exposure_treatment.csv\n20220215_patient-exposure_control.csv\n20220215_patient-exposure_treatment.csv\n20220215_patient-info_control.csv\n20220310_patient-info_control.csv\n20220520_patient-info_treatment.csv\n20220805_patient-info_control.csv\n\n\nâ¯ ls -1 *info*\n20220215_patient-info_control.csv\n20220310_patient-info_control.csv\n20220520_patient-info_treatment.csv\n20220805_patient-info_control.csv\n20230120_patient-info_treatment.csv\n20230215_patient-info_treatment.csv\n20230405_patient-info_control.csv\n20230615_patient-info_treatment.csv\n20230710_patient-info_control.csv\n20230710_patient-info_treatment.csv\n20230805_patient-info_treatment.csv\n\n\n\n\n\n\nRegular Expression and Globbing Friendly:\n\nFile names should be crafted to be easily processed using regular expressions and globbing (wildcard) patterns.\nConsider avoiding spaces, punctuation, accented characters, and maintain case sensitivity for consistency in manipulation.\n\nEasy to Compute On:\n\nIntentionally use delimiters in file names, making them straightforward for computational processes.\nDeliberate use of delimiters enhances the efficiency of computations.\n\nDiscuss searches shown, impossible with inconsistent file names"
  },
  {
    "objectID": "presentations/20240131-RBP.html#human-readable",
    "href": "presentations/20240131-RBP.html#human-readable",
    "title": "Best Practices in R",
    "section": "Human Readable ğŸ“‘",
    "text": "Human Readable ğŸ“‘\n\n\n\nInformative File Names:\n\nInclude content information in file names\nAnticipate usage context\n\nSlug:\n\nUser-friendly and descriptive filenames\n20230710_*patient-info_control*.csv\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiledir &lt;- here(\"presentations/20240131-RBP_images/fakedat/\")\nflist &lt;- list.files(filedir, pattern = \"info\")\n\nstringr::str_split_fixed(flist, \"[_\\\\.]\", 4)\n\n      [,1]       [,2]           [,3]        [,4] \n [1,] \"20220215\" \"patient-info\" \"control\"   \"csv\"\n [2,] \"20220310\" \"patient-info\" \"control\"   \"csv\"\n [3,] \"20220520\" \"patient-info\" \"treatment\" \"csv\"\n [4,] \"20220805\" \"patient-info\" \"control\"   \"csv\"\n [5,] \"20230120\" \"patient-info\" \"treatment\" \"csv\"\n [6,] \"20230215\" \"patient-info\" \"treatment\" \"csv\"\n [7,] \"20230405\" \"patient-info\" \"control\"   \"csv\"\n [8,] \"20230615\" \"patient-info\" \"treatment\" \"csv\"\n [9,] \"20230710\" \"patient-info\" \"control\"   \"csv\"\n[10,] \"20230710\" \"patient-info\" \"treatment\" \"csv\"\n[11,] \"20230805\" \"patient-info\" \"treatment\" \"csv\"\n\n\n\n\n\n\n\n\nInformative Naming:\n\nEnsure that the name of the file contains information about its content.\nAnticipate the context in which the file will be used, to facilitate understanding\n\nIf in a context where dates are less important than say, organism, lead with the more appropriate chunk\n\n\nSlug Concept:\n\nImplement the concept of a slug in your filenames: creating user-friendly and descriptive URLs for better comprehension.\nA slug is often defined as the part of a URL that identifies a page in human-readable keywords\n\nEasy parsing due to consistent use of delimiters"
  },
  {
    "objectID": "presentations/20240131-RBP.html#easy-sorting",
    "href": "presentations/20240131-RBP.html#easy-sorting",
    "title": "Best Practices in R",
    "section": "Easy Sorting ğŸ“‘",
    "text": "Easy Sorting ğŸ“‘\n\nNumeric Inclusion:\n\nOften for code\nInclude a numeric element for effective sorting\nLeft-pad with zeros for consistent width and visual sorting.\neg 01_import.R\n\nDates:\n\nUtilize the ISO 8601 standard for date formatting: YYYYMMDD\nEnsures chronological sorting in file names by default\neg 20220820_wedding-photos.zip\n\n\n\n\nNumeric Inclusion:\n\nInclude something numeric in the file name for effective sorting of scripts.\nLeft-pad numeric elements with zeros to maintain a constant width for visually pleasing and consistent sorting.\n\nISO 8601 Standard for Dates:\n\nUse the ISO 8601 standard for dates in file names to ensure chronological sorting by default.\n\nCommon-Sense Ordering:\n\nConsider common-sense ordering based on the nature of the data or content.\nEnsure that the file names sort logically for easier retrieval."
  },
  {
    "objectID": "presentations/20240131-RBP.html#naming-conventions-1",
    "href": "presentations/20240131-RBP.html#naming-conventions-1",
    "title": "Best Practices in R",
    "section": "Naming Conventions ğŸ“‘",
    "text": "Naming Conventions ğŸ“‘\n\nAvoid:\n\nInternal sequential numbers: result1.csv, result2.csv\nManuscript locations: fig_3_a.png\n\n\n\n\nAvoid:\n\nSequential numbers: result1.csv, result2.csv\n\nDifficult to parse, non-standard\n\nManuscript locations: fig_3_a.png\n\nLiable to change"
  },
  {
    "objectID": "presentations/20240131-RBP.html#section-1",
    "href": "presentations/20240131-RBP.html#section-1",
    "title": "Best Practices in R",
    "section": "",
    "text": "Everything that matters should be achieved through saved code\n\n\n\nAll important objects or figures should be explicitly saved to file, via code\nSave source, not the environmentâ€¦"
  },
  {
    "objectID": "presentations/20240131-RBP.html#meaningful-comments",
    "href": "presentations/20240131-RBP.html#meaningful-comments",
    "title": "Best Practices in R",
    "section": "Meaningful Comments ğŸ’¬",
    "text": "Meaningful Comments ğŸ’¬\nRule 1: Comments should not duplicate the code"
  },
  {
    "objectID": "presentations/20240131-RBP.html#rule1",
    "href": "presentations/20240131-RBP.html#rule1",
    "title": "Best Practices in R",
    "section": "",
    "text": "if (x &gt; 3) {\n   â€¦\n} # close if\n\n\n\n\ni = i + 1 # Add one to i\n\n\n\n\n\nStack Overflow blog in resources with 10 rules, lets consider 3\n\nRule 1: Comments should not duplicate the code.\n\nTraining wheels carried over from early learning exercises\nadd visual clutter\nwaste time writing, reading, and updating for no gain\nIt adds no information whatsoever and incurs a maintenance cost."
  },
  {
    "objectID": "presentations/20240131-RBP.html#meaningful-comments-1",
    "href": "presentations/20240131-RBP.html#meaningful-comments-1",
    "title": "Best Practices in R",
    "section": "Meaningful Comments ğŸ’¬",
    "text": "Meaningful Comments ğŸ’¬\nRule 2: Good comments do not excuse unclear code."
  },
  {
    "objectID": "presentations/20240131-RBP.html#rule2",
    "href": "presentations/20240131-RBP.html#rule2",
    "title": "Best Practices in R",
    "section": "",
    "text": "getBestChildNode &lt;- function(node) {\n  n &lt;- NULL  # best child node candidate\n  for (child_node in node$children) {\n    # update n if the current state is better\n    if (is.null(n) || utility(child_node) &gt; utility(n)) {\n      n &lt;- child_node\n    }\n  }\n  return(n)\n}\n\n\n\n\ngetBestChildNode &lt;- function(node) {\n  bestNode &lt;- NULL\n  for (currentNode in node$children) {\n    if (is.null(bestNode) || utility(currentNode) &gt; utility(bestNode)) {\n      bestNode &lt;- currentNode\n    }\n  }\n  return(bestNode)\n}\n\n\n\n\n- Rule 2: Good comments do not excuse unclear code.\n    - For example generic variable names (x, y, etc) explained in comments\n    - Need for comments is reduced if variables are named properly"
  },
  {
    "objectID": "presentations/20240131-RBP.html#meaningful-comments-2",
    "href": "presentations/20240131-RBP.html#meaningful-comments-2",
    "title": "Best Practices in R",
    "section": "Meaningful Comments ğŸ’¬",
    "text": "Meaningful Comments ğŸ’¬\nRule 3: If you canâ€™t write a clear comment, there may be a problem with the code.\n\n\nRule 3: If you canâ€™t write a clear comment, there may be a problem with the code."
  },
  {
    "objectID": "presentations/20240131-RBP.html#section-4",
    "href": "presentations/20240131-RBP.html#section-4",
    "title": "Best Practices in R",
    "section": "",
    "text": "â€œDebugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.â€\n\n\n\nBrian Kernighan\n\nIf you canâ€™t explain it simply, you donâ€™t understand it well enough\nRewrite the code to something you understand well enough to explain or, better yet, that is straightforward."
  },
  {
    "objectID": "presentations/20240131-RBP.html#roxygen2-comments",
    "href": "presentations/20240131-RBP.html#roxygen2-comments",
    "title": "Best Practices in R",
    "section": "Roxygen2 Comments ğŸ’¬",
    "text": "Roxygen2 Comments ğŸ’¬\n\n\nRoxygen2 allows you to avoid the awful practice of documenting packages where you write .Rd files by hand."
  },
  {
    "objectID": "presentations/20240131-RBP.html#roxygen2-comments-1",
    "href": "presentations/20240131-RBP.html#roxygen2-comments-1",
    "title": "Best Practices in R",
    "section": "Roxygen2 Comments ğŸ’¬",
    "text": "Roxygen2 Comments ğŸ’¬\n\n\n\nIn-line documentation\nRich, dynamic .Rd file generation\nStandard markdown\n\n\n\n\n\n#' Add together two numbers\n#' \n#' @param x A number.\n#' @param y A number.\n#' @returns A numeric vector.\n#' @examples\n#' add(1, 1)\n#' add(10, 1)\nadd &lt;- function(x, y) {\n  x + y\n}\n\n\n\n% Generated by roxygen2: do not edit by hand\n% Please edit documentation in R/add.R\n\\name{add}\n\\alias{add}\n\\title{Add together two numbers}\n\\usage{\nadd(x, y)\n}\n\\arguments{\n\\item{x}{A number.}\n\n\\item{y}{A number.}\n}\n\\value{\nA numeric vector.\n}\n\\description{\nAdd together two numbers\n}\n\\examples{\nadd(1, 1)\nadd(10, 1)\n}\n\n\n\n\n\nThere are a few advantages to using roxygen2 : - Code and documentation are co-located. When you modify your code, itâ€™s easy to remember to also update your documentation. - roxygen2 provides a number of tools for sharing content across documentation topics and even between topics and vignettes. - Thereâ€™s a lot of .Rd boilerplate thatâ€™s automated away. - You can use markdown, rather than having to learn a one-off markup language that only applies to .Rd files. In addition to formatting, the automatic hyperlinking functionality makes it much, much easier to create richly linked documentation."
  },
  {
    "objectID": "presentations/20240131-RBP.html#roxygen2-comments-2",
    "href": "presentations/20240131-RBP.html#roxygen2-comments-2",
    "title": "Best Practices in R",
    "section": "Roxygen2 Comments ğŸ’¬",
    "text": "Roxygen2 Comments ğŸ’¬\n\n\n\nAllow for easy bundling of inline documentation into a website"
  },
  {
    "objectID": "presentations/20240131-RBP.html#modular-and-reusable-code",
    "href": "presentations/20240131-RBP.html#modular-and-reusable-code",
    "title": "Best Practices in R",
    "section": "Modular and Reusable Code ğŸ£",
    "text": "Modular and Reusable Code ğŸ£\n\nStart programs/functions with explanatory comments.\nUse meaningful names for functions and variables.\nExplicitly state dependencies and requirements.\nAvoid commenting/uncommenting code sections for program control.\nInclude a simple example or test data set for clarity.\n\n\n\nAs weâ€™ve already discussed\nWriting functions and scripts for modularity\n\nPlace a brief explanatory comment at the start of every program or function\nGive functions and variables meaningful names.\nMake dependencies and requirements explicit.\nDo not comment and uncomment sections of code to control a programâ€™s behavior.\n\nIf itâ€™s going to be shared\nUse proper conditionals or remove\n\nProvide a simple example or test data set.\n\nWhat is the ultimate version of this process?"
  },
  {
    "objectID": "presentations/20240131-RBP.html#make-an-r-package",
    "href": "presentations/20240131-RBP.html#make-an-r-package",
    "title": "Best Practices in R",
    "section": "Make an R Package ğŸ£",
    "text": "Make an R Package ğŸ£\n\nWhy make an R package?\n\nCode Organization\nConsistent documentation\nCode Distribution\nDependency handling\n\n\n\n\nCreating R packages for code reuse and distribution Why make an R package?\n\n\nCode Organization: I am always trying to figure out where that â€œfunctionâ€ I wrote months, weeks, or even days ago. Often times, I end up just re-writing it because it is faster than searching all my .R files. An R package would help in organizing where my functions go.\nConsistent documentation: I can barely remember what half of my functions do let alone the inputs and outputs. An R package provides a great consistent documentation structure and actually encourages you to document your functions.\nCode Distribution: No more emailing .R scripts! An R package gives an easy way to distribute your code for others. Especially if you put it on GitHub.\nDependency handling: No more failing scripts because library calls failed on load. Install the package and all of its dependencies are installed alongside it!\n\n\nEven if itâ€™s just for yourself"
  },
  {
    "objectID": "presentations/20240131-RBP.html#make-an-r-package-1",
    "href": "presentations/20240131-RBP.html#make-an-r-package-1",
    "title": "Best Practices in R",
    "section": "Make an R Package ğŸ£",
    "text": "Make an R Package ğŸ£\n\n\n\nPackage directory structure\n\nScripts in R\nDocumentation in man\nREADME.md\nDESCRIPTION\nNAMESPACE\n\n{Roxygen2} for documentation\n{devtools} for process\n\n\n.\nâ”œâ”€â”€ DESCRIPTION\nâ”œâ”€â”€ NAMESPACE\nâ”œâ”€â”€ R\nâ”‚   â”œâ”€â”€ cat_function.R\nâ”‚   â”œâ”€â”€ cat_images.R\nâ”‚   â””â”€â”€ cats-package.R\nâ”œâ”€â”€ README.md\nâ””â”€â”€ man\n    â”œâ”€â”€ add_cat.Rd\n    â”œâ”€â”€ cat_function.Rd\n    â”œâ”€â”€ cats.Rd\n    â”œâ”€â”€ get_cat.Rd\n    â””â”€â”€ here_kitty.Rd\n\n\n\n\nR packages are easy\nMaking an R package involves creating a specific structure of directory and adding specific files\nPackage directory structure\n\nScripts in R\nDocumentation in man (automated)\nREADME.md\nDESCRIPTION\nNAMESPACE (automated)\n\nEasily accomplished with Roxygen2 and devtools\nThis is the directory structure of the cats package linked in resources"
  },
  {
    "objectID": "presentations/20240131-RBP.html#make-an-r-package-2",
    "href": "presentations/20240131-RBP.html#make-an-r-package-2",
    "title": "Best Practices in R",
    "section": "Make an R Package ğŸ£",
    "text": "Make an R Package ğŸ£\n\n\n\nGH for the cats package from HPâ€™s very approachable â€œWriting an R package from scratchâ€ blog entry\nReadme rendered from markdown"
  },
  {
    "objectID": "presentations/20240131-RBP.html#make-an-r-package-3",
    "href": "presentations/20240131-RBP.html#make-an-r-package-3",
    "title": "Best Practices in R",
    "section": "Make an R Package ğŸ£",
    "text": "Make an R Package ğŸ£\n\n\n\nDESCRIPTION file\n\nDependencies\nPackage metadata\nContact information\n\n\n\nPackage: cats\nTitle: Cats\nVersion: 0.1\nAuthor: Hilary Parker &lt;hilary@etsy.com&gt; [aut, cre]\nMaintainer: Hilary Parker &lt;hilary@etsy.com&gt;\nAuthors@R: c( person(\"Hilary\", \"Parker\", email = \"hilary@etsy.com\", role =\n    c(\"aut\", \"cre\")))\nDescription: Mew.\nDepends:\n    R (&gt;= 3.0.2)\nImports:\n    httr,\n    ggplot2,\n    jpeg\nLicense: MIT\nLazyData: true\nSuggests:\n    testthat\n\n\n\n\nThe job of the DESCRIPTION file is to store important metadata about your package.\nEarly on, use these metadata to record what packages are needed to run your package.\nand information about it\nLater, if released publicly let people get in touch with you!"
  },
  {
    "objectID": "presentations/20240131-RBP.html#version-control",
    "href": "presentations/20240131-RBP.html#version-control",
    "title": "Best Practices in R",
    "section": "Version Control ğŸ§­",
    "text": "Version Control ğŸ§­\nWhy version control in data analysis projects?\n\n\n\nFile Versioning\nFigure Recreation\nCode Modification Impact\nDirectory Copying Fear\nShared File Row Duplication\nLost Data Files\nAnalysis Choice\n\n\n\nManuscript Collaboration Merge\nAccidental Deletion\nProject Status Recall\nExperiment Mistake Identification\nDirectory Pollution\nSelective Changes\nAd Infinitum\n\n\n\n\nI have fifteen versions of this file and I donâ€™t know which is which I canâ€™t remake this figure from last year I modified my code and something apparently unrelated does not work anymore I have several copies of the same directory because Iâ€™m worried about breaking something Somebody duplicated a record in a shared file with samples You remember seeing a data file but cannot find it anymore: is it deleted ? Moved away ? I tried multiple analysis and I donâ€™t remember which one I chose to generate my output data I have to merge changes to a paper from mails with collaborators I accidentally deleted a part of my work I came to an old project and forgot where I left it I have trouble to find the source of a mistake in an experiment My directory is polluted with a lot of unused/temporary/old folders because Iâ€™m afraid of losing something important I made a lot of changes to my paper but only want to bring back one of paragraph\nMany Reasons"
  },
  {
    "objectID": "presentations/20240131-RBP.html#version-control-1",
    "href": "presentations/20240131-RBP.html#version-control-1",
    "title": "Best Practices in R",
    "section": "Version Control ğŸ§­",
    "text": "Version Control ğŸ§­"
  },
  {
    "objectID": "presentations/20240131-RBP.html#version-control-2",
    "href": "presentations/20240131-RBP.html#version-control-2",
    "title": "Best Practices in R",
    "section": "Version Control ğŸ§­",
    "text": "Version Control ğŸ§­\n\nWhat to Save:\n\nHuman-created content.\nPlain text files.\nAvoid binary files.\n\n\n\n\nWhat to save?\n\nBack up (almost) everything created by a human being as soon as it is created\nOptimized for plain text files (scripts) and can pinpoint changes between versions\nDoesnâ€™t work well for binary files like PDFs or MS Office files\nRaw data shouldnâ€™t change and intermediate files should be able to be reproduced by saved source so no need to change"
  },
  {
    "objectID": "presentations/20240131-RBP.html#version-control-manual",
    "href": "presentations/20240131-RBP.html#version-control-manual",
    "title": "Best Practices in R",
    "section": "Version Control: Manual ğŸ§­",
    "text": "Version Control: Manual ğŸ§­\nCHANGELOG.txt\n## 2016-04-08\n\n* Switched to cubic interpolation as default.\n* Moved question about family's TB history to end of questionnaire.\n\n## 2016-04-06\n\n* Added option for cubic interpolation.\n* Removed question about staph exposure (can be inferred from blood test results).\n\nAdd a file called CHANGELOG.txt to the projectâ€™s docs subfolder and make dated notes about changes to the project in this file in reverse chronological order (i.e., most recent first). This file is the equivalent of a lab notebook, and should contain entries like those shown."
  },
  {
    "objectID": "presentations/20240131-RBP.html#version-control-manual-1",
    "href": "presentations/20240131-RBP.html#version-control-manual-1",
    "title": "Best Practices in R",
    "section": "Version Control: Manual ğŸ§­",
    "text": "Version Control: Manual ğŸ§­\nBackup entire project folder\n.\n|-- project_name\n|   -- current\n|       -- ...project content as described earlier...\n|   -- 2016-03-01\n|       -- ...content of 'current' on Mar 1, 2016\n|   -- 2016-02-19\n|       -- ...content of 'current' on Feb 19, 2016\n\nâ€¦ please donâ€™t do this\n\n\nCopy the entire project whenever a significant change has been made (i.e., one that materially affects the results), and store that copy in a sub-folder whose name reflects the date in the area thatâ€™s being synchronized. This approach results in projects being organized as shown above"
  },
  {
    "objectID": "presentations/20240131-RBP.html#version-control-vcs",
    "href": "presentations/20240131-RBP.html#version-control-vcs",
    "title": "Best Practices in R",
    "section": "Version Control: VCS ğŸ§­",
    "text": "Version Control: VCS ğŸ§­\n\nVersion Control System\nEfficient Backup Storage\nAutomated Timestamps\nAutomated Changelog and Accuracy\nConflict Resolution and Merging\nExamples: Git, SVN, Bitbucket, etc\n\n\n\nVCS\nMuch better than manual\nEfficient Backup Storage:\n\nVersion control eliminates the need for users to create backup copies of the entire project.\nSafely stores sufficient information to recreate old versions of files on demand.\n\nAutomated Timestamps:\n\nTimestamps all saved changes automatically, eliminating the reliance on users to choose sensible names for backup copies.\n\nAutomated Changelog and Accuracy:\n\nVersion control systems prompt users whenever a change is saved, ensuring a disciplined approach without relying on manual changelogs.\nMaintains a 100% accurate record of actual changes made, valuable for troubleshooting later.\n\nConflict Resolution and Merging:\n\nInstead of blindly copying files to remote storage, version control checks for potential overwrites of othersâ€™ work.\nFacilitates conflict identification and merging changes, ensuring collaboration without loss of data.\n\nLinks to very good tutorials in the resources section of this talk"
  },
  {
    "objectID": "presentations/20240131-RBP.html#managing-project-dependencies",
    "href": "presentations/20240131-RBP.html#managing-project-dependencies",
    "title": "Best Practices in R",
    "section": "Managing Project Dependencies ğŸ“¦",
    "text": "Managing Project Dependencies ğŸ“¦"
  },
  {
    "objectID": "presentations/20240131-RBP.html#section-5",
    "href": "presentations/20240131-RBP.html#section-5",
    "title": "Best Practices in R",
    "section": "",
    "text": "â€œDebugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.â€\n\n\n\nBrian Kernighan\n\nIf you canâ€™t explain it simply, you donâ€™t understand it well enough\nRewrite the code to something you understand well enough to explain or, better yet, that is straightforward."
  },
  {
    "objectID": "presentations/20240131-RBP.html#managing-project-dependencies-1",
    "href": "presentations/20240131-RBP.html#managing-project-dependencies-1",
    "title": "Best Practices in R",
    "section": "Managing Project Dependencies ğŸ“¦",
    "text": "Managing Project Dependencies ğŸ“¦\n\nWhat is the environment?\n\nThe version of the software used\n- R 3.6.1 vs R 4.3.2\nThe versions of the packages/extensions used\n- {dplyr} 1.0.10 vs 1.1.12\nExternal software dependencies for packages\n- pandoc\n\n\n\n\nWhat is the environment?\n\nThe version of the software used\nThe versions of the packages/extensions used\nExternal software dependencies for packages (eg. pandoc)\n\nChallenges associated with package versions and dependencies in R projects\n\nOften your code will run without any hiccups even when environments differ. Software engineers try to make sure your code will not stop working if you use a slightly different versions.\nBut with all the software and all the dependencies eventually something will give and things will break. Even if the code runs successfully, there is a chance that the results could differ.\n\nManually comparing environments is difficult to impossible, using containers to replicate anotherâ€™s computer is complex so we recommend a mid-point: ensuring package and R versions are the same each time the analysis is run"
  },
  {
    "objectID": "presentations/20240131-RBP.html#httptinyurl.comcogseminar",
    "href": "presentations/20240131-RBP.html#httptinyurl.comcogseminar",
    "title": "Best Practices in R",
    "section": "http://tinyurl.com/COGseminar",
    "text": "http://tinyurl.com/COGseminar"
  },
  {
    "objectID": "presentations/20240131-RBP.html#seminar-content",
    "href": "presentations/20240131-RBP.html#seminar-content",
    "title": "Best Practices in R",
    "section": "Seminar Content",
    "text": "Seminar Content\n\n\nWhat they forgot to teach you in R\nVersion Control with Git and Github\nGood Enough Practices in Scientific Computing - Paper\nGood Enough Practices in Scientific Computing - Course\nThe Turing Way\nProject Oriented Workflow Slides\nMy Previous R Course\nR for Data Science"
  },
  {
    "objectID": "presentations/20240131-RBP.html#moodle-cources",
    "href": "presentations/20240131-RBP.html#moodle-cources",
    "title": "Best Practices in R",
    "section": "Moodle Cources",
    "text": "Moodle Cources\n\n\nIntroduction to Git\nOther R Courses"
  },
  {
    "objectID": "presentations/20240131-RBP.html#readability-1",
    "href": "presentations/20240131-RBP.html#readability-1",
    "title": "Best Practices in R",
    "section": "Readability",
    "text": "Readability\n\n\nCode Tells You How, Comments Tell You Why\nBest practices for writing code comments\nRoxygen for in-line documentation\nQuarto for reports\npkgdown to compile into websites"
  },
  {
    "objectID": "presentations/20240131-RBP.html#packages",
    "href": "presentations/20240131-RBP.html#packages",
    "title": "Best Practices in R",
    "section": "Packages",
    "text": "Packages\n\n\nR Packages\nYour first R package in 1 hour\nWriting an R package from scratch\nMaking Your First R Package"
  },
  {
    "objectID": "presentations/20240131-RBP.html#project-dependencies",
    "href": "presentations/20240131-RBP.html#project-dependencies",
    "title": "Best Practices in R",
    "section": "Project Dependencies",
    "text": "Project Dependencies\n\n\nrenv Documentation\nReproducible R Toolbox\nReproducibility with renv"
  },
  {
    "objectID": "presentations/20240131-RBP.html#useful-links",
    "href": "presentations/20240131-RBP.html#useful-links",
    "title": "Best Practices in R",
    "section": "Useful Links",
    "text": "Useful Links\n\n\nCheatsheets\nHacker Laws\nReproducible Reporting with R"
  },
  {
    "objectID": "presentations/20240131-RBP.html#section-2",
    "href": "presentations/20240131-RBP.html#section-2",
    "title": "Best Practices in R",
    "section": "",
    "text": "Programs must be written for people to read, and only incidentally for machines to execute."
  },
  {
    "objectID": "presentations/20240131-RBP.html#section-6",
    "href": "presentations/20240131-RBP.html#section-6",
    "title": "Best Practices in R",
    "section": "",
    "text": "The only way to be certain that code written by someone else will run on your machine and will produce the same results is to replicate their environment\n\n\nmanaging project dependencies is a significant issue"
  },
  {
    "objectID": "presentations/20240131-RBP.html#make-an-r-package-4",
    "href": "presentations/20240131-RBP.html#make-an-r-package-4",
    "title": "Best Practices in R",
    "section": "Make an R Package ğŸ£",
    "text": "Make an R Package ğŸ£\n\n\n\nNAMESPACE file\n\nFunctions from your package\nImported functions from others\n\n\n\n\n# Generated by roxygen2 (4.0.1.99): do not edit by hand\n\nexport(add_cat)\nexport(cat_function)\nexport(get_cat)\nexport(here_kitty)\nimport(ggplot2)\nimport(httr)\nimport(jpeg)\n\n\n\n\nThe NAMESPACE file specifies which functions your package makes available for others to use and, optionally, imports functions from other packages.\nalt-tab to terminal to show package contents?\nAlready showed a quick picture of github which is a bit of a teaser for our next sectionâ€¦"
  },
  {
    "objectID": "presentations/20240131-RBP.html#version-control-vcs-1",
    "href": "presentations/20240131-RBP.html#version-control-vcs-1",
    "title": "Best Practices in R",
    "section": "Version Control: VCS ğŸ§­",
    "text": "Version Control: VCS ğŸ§­\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTwo prominent VCS websites that both use Git"
  },
  {
    "objectID": "presentations/20240131-RBP.html#version-control-vcs-2",
    "href": "presentations/20240131-RBP.html#version-control-vcs-2",
    "title": "Best Practices in R",
    "section": "Version Control: VCS ğŸ§­",
    "text": "Version Control: VCS ğŸ§­\n\n\nA side benefit of using these VCS systems and sites is easy hosting of content, from package documentation to presentations like this one\n\nNow that weâ€™re tracking our code how do we make sure it continues to work?"
  }
]